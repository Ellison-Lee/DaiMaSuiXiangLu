# Shopee面经

# 一面

> 一面主要以基础为主，MySQL，大数据组件，手撕算法题和SQL题

### 数据倾斜的场景和解决方法

数据倾斜的本质是：**在分布式处理时，某个或某几个分区的数据量远远超过其他分区**，导致“少数几个节点干活特别慢，其他节点早早就干完等着”的情况。这会造成资源利用率极低、任务执行时间很长，甚至导致节点内存溢出（OOM）和任务失败。

一、数据倾斜的常见场景                                                                                                                                                                                 

1. **Group By / Key Aggregation（分组聚合）**
   - **场景**：当我们对某个字段进行 `GROUP BY` 或 `COUNT DISTINCT` 时，如果这个字段存在大量相同值或极少数值（比如 null 值、默认值、枚举值），那么这些“热点key”的数据会被发往同一个 Reduce Task 或 Spark 的同一个 Partition，导致该节点压力巨大。
   - **例子**：统计某个App的日活用户，但数据中90%的 `user_id` 字段因为埋点问题都是 `0` 或 `null`。
2. **Join（表关联）**
   - **场景**：在进行两张表的关联操作时（尤其是 Reduce Side Join/Common Shuffle Join），如果其中一张表的关联键存在大量重复，或者是一张小表但某个key的数据量异常大，就会在Shuffle过程中造成倾斜。
   - **例子**：一张巨大的用户行为表 `log`（几十亿行）与一张较小的维度表 `city`（几百行）进行 `INNER JOIN`。如果 `city` 表中有一个“未知城市”的key（比如 `city_id = 0`），而 `log` 表中90%的记录其 `city_id` 都恰好是 `0`，那么所有 `city_id = 0` 的数据都会被拉到同一个Reduce节点上与 `city` 表进行关联，瞬间就会压垮这个节点。
3. **数据源本身不均匀**
   - **场景**：数据文件本身就被写入到少数几个数据块中，或者 Kafka 等消息队列的某个 Topic Partition 数据量激增。

二、数据倾斜的解决方法

解决思路通常分为两类：**业务逻辑优化**和**技术层面优化**。

1. 业务逻辑优化（从源头避免）

- **过滤无效数据**：在聚合或关联前，先检查并过滤掉导致倾斜的异常key，比如大量的 `null`、测试数据、默认值等。
- **业务层面规避**：与业务方沟通，是否可以换一个更均匀的维度进行统计。这是最根本的解决方法。

针对group by

- **增加 Shuffle 并行度**：通过调大 `spark.sql.shuffle.partitions` 或 `hive.exec.reducers.bytes.per.reducer` 参数，增加 Reduce 任务数，让数据被分配到更多节点上。**这种方法对于只有一个倾斜key的情况效果有限**，因为那个巨大的key最终还是会被分到一个分区里。

- **两阶段聚合（加盐扩容 -> 聚合 -> 去盐聚合）**：这是处理严重倾斜的“大招”。
  1. **加盐**：给热点key添加一个随机数前缀（如 `key_1`, `key_2`, ..., `key_n`），将原来一个key的数据打散到多个分区中去。
  2. **第一阶段聚合**：对打散后的数据（`key_1`, `key_2`）进行第一次聚合。
  3. **第二阶段聚合**：将随机数前缀去掉，再对第一次聚合的结果进行最终的全局聚合。

针对join：

- **拆分倾斜键**：

  1. 将倾斜的key（如 `city_id = 0`）从数据中单独过滤出来。
  2. 倾斜key的数据集与维度表单独进行 Map Join（因为此时这个key对应的维度表数据可能也很小）。
  3. 非倾斜key的数据集正常进行 Reduce Join。
  4. 将两部分结果进行 `UNION ALL` 合并。

  

### time_wait 了解吗，服务器大量处于time_wait状态，可能是什么原因？

关于 `TIME_WAIT` 状态，我了解它是 TCP 四次挥手过程中主动关闭连接的一方会进入的状态。

首先，我来解释一下它的作用和产生原因：

1. 什么是 TIME_WAIT？

在 TCP 四次挥手结束时，**主动发起关闭连接的一方**（比如，先调用 `close()` 的一方）会进入 `TIME_WAIT` 状态。这个状态会持续一段时间，通常是 **2MSL**（MSL：Maximum Segment Lifetime，报文最大生存时间，在 Linux 中一般定义为 60秒，所以 TIME_WAIT 通常为 120秒）。

2. 为什么需要 TIME_WAIT？

它主要有两个核心作用：

1. **可靠地关闭连接**：确保最后一个 ACK 报文能被对端收到。如果这个 ACK 报文丢失，对端（处于 LAST_ACK 状态）会超时重发最终的 FIN 报文。主动关闭方在 `TIME_WAIT` 状态下收到这个重发的 FIN 后，可以再次发出 ACK，从而保证连接被正常关闭。如果没有这个状态，主动关闭方在发出 ACK 后就完全消失了，对端将一直处于 LAST_ACK 状态，无法正常关闭。
2. **让旧的报文段在网络中消逝**：防止**之前连接的延迟报文**被**新的、相同四元组（源IP、源端口、目的IP、目的端口）的连接**错误地接收。这 2MSL 的等待时间足以让本次连接产生的所有报文都在网络中失效，从而不会干扰新的连接。

3. 服务器大量出现 TIME_WAIT 的原因及影响

您问到的“服务器大量处于 TIME_WAIT 状态”，这是一个非常典型的场景。

- **根本原因**：**服务器主动关闭了大量的 TCP 连接**。

- **典型场景**：

  1. **HTTP 服务**：在 HTTP 1.1 之前，协议设计是默认使用短连接（Connection: close）。这意味着服务器处理完一个请求后，**会主动关闭连接**。如果一个服务器被大量客户端（如移动APP后端、Web服务器）频繁请求，就会产生大量的短连接，而关闭这些连接的主动权又在服务器这边，自然会导致服务器上出现成千上万的 `TIME_WAIT` 连接。
  2. **爬虫或代理服务器**：代理服务器在帮客户端向目标服务器获取数据后，也会主动关闭与目标服务器的“上游连接”，从而产生大量 `TIME_WAIT`。
  3. **某些特定的 API 调用或负载均衡器**：也可能遵循类似的模式。

- **可能造成的影响**：

  1. **资源占用**：每个 `TIME_WAIT` 连接都会占用一个【本地IP、本地端口】的元组资源。虽然内存占用不大，但 TCP 端口号是有限的（最多 65535 个）。
  2. **端口耗尽**：这是最严重的问题。当 `TIME_WAIT` 连接数量巨大，耗尽了所有可用端口，新的连接就无法建立（会看到 “Cannot assign requested address” 等错误）。因为新连接需要绑定一个本地端口，而所有端口都处于 `TIME_WAIT` 状态尚未释放。

  

### 数据库索引结构？数据到达时怎么走的查询过程？

一、数据库索引的核心结构：B+树

绝大多数关系型数据库（如 MySQL InnoDB, PostgreSQL）的默认索引结构都是 **B+树**。之所以选择它，是因为它非常适合磁盘存储和范围查询。

**B+树的特点：**

1. **多路平衡搜索树**：它是“矮胖”型的树结构，每个节点可以有多个子节点（大大减少树的高度）。查询任何数据所需的磁盘 I/O 次数基本稳定（通常只需 3-4 次），效率极高。
2. **数据有序存储**：所有节点内的键值（Key）都是按顺序排列的，这使得范围查询（`WHERE id > 100`）、排序和分组操作非常高效。
3. **数据只存储在叶子节点**：B+树的所有数据记录（Row Data）都存放在最底层的叶子节点上。而非叶子节点（内部节点）只存储**键值**和**指向子节点的指针**，起到一个路由导航的作用。
4. **叶子节点通过指针串联**：所有叶子节点之间用一个双向链表连接起来。这个设计让范围查询不再需要回溯到父节点，直接通过链表遍历下一个叶子节点即可，性能极高。

MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，

### Mysql的数据结构

MySQL 的数据结构设计核心目标是**减少磁盘 I/O**，因为磁盘读写是数据库操作中最慢的环节。为此，InnoDB 采用了 **页（Page）** 作为磁盘和内存交互的基本单位（通常是 16KB），并使用了 **B+树** 作为索引和数据组织的基本结构。

### JOIN语句如何使用？如何优化？

一、JOIN 语句的使用

SQL 标准中定义了多种 JOIN 操作，最常用的有以下几种：

**假设我们有两个表：**

- `employees` (员工表): `emp_id`, `emp_name`, `dept_id`
- `departments` (部门表): `dept_id`, `dept_name`

1. INNER JOIN (内连接)

**作用**：返回两个表中**连接键完全匹配**的行。
**语法**：

sql

```
SELECT e.emp_name, d.dept_name
FROM employees e
INNER JOIN departments d ON e.dept_id = d.dept_id;
```

**结果**：只列出有明确部门的员工及其部门信息。如果一个员工没有部门(`dept_id`为NULL或不在部门表中)，或者一个部门没有任何员工，则都不会出现在结果中。

2. LEFT (OUTER) JOIN (左外连接)

**作用**：返回**左表**的全部行，即使右表中没有匹配的行。如果右表无匹配，则右表字段以NULL填充。
**语法**：

sql

```
SELECT e.emp_name, d.dept_name
FROM employees e
LEFT JOIN departments d ON e.dept_id = d.dept_id;
```

**结果**：列出所有员工。如果某个员工（如'张三'）的`dept_id`在部门表中找不到，他的`dept_name`字段会显示为NULL。**（常用：统计所有用户的行为，即使用户没有行为也要保留）**

3. RIGHT (OUTER) JOIN (右外连接)

**作用**：与左连接相反，返回**右表**的全部行，即使左表中没有匹配的行。
**语法**：

sql

```
SELECT e.emp_name, d.dept_name
FROM employees e
RIGHT JOIN departments d ON e.dept_id = d.dept_id;
```

**结果**：列出所有部门。即使某个部门（如'后勤部'）没有任何员工，该部门也会被列出，对应的`emp_name`为NULL。**（较少使用，通常用左连接替代）**

4. FULL (OUTER) JOIN (全外连接)

**作用**：返回左右两表的并集。只要某一边表中有记录，就会被返回。
**语法**（MySQL不支持，但Oracle/PostgreSQL支持）：

sql

```
SELECT e.emp_name, d.dept_name
FROM employees e
FULL OUTER JOIN departments d ON e.dept_id = d.dept_id;
```

**结果**：所有员工 + 所有部门。不匹配的地方都用NULL填充。

5. CROSS JOIN (交叉连接)

**作用**：返回两表的笛卡尔积，即左表的每一行与右表的每一行进行组合。
**语法**：

sql

```
SELECT e.emp_name, d.dept_name
FROM employees e
CROSS JOIN departments d;
```

**结果**：如果员工表有100行，部门表有10行，结果将是1000行。**（通常需要避免，除非业务需要）**

二、JOIN 的优化策略

JOIN 操作非常消耗资源，优化是数据开发中的重中之重。我的优化思路是从基础到高级，从预防到解决。

1. 基础优化（重中之重）

- **确保有关联键的索引**：这是最有效的一条。**必须**在JOIN条件（`ON`子句）的字段上建立索引。

  - 对于 `employees.dept_id` 和 `departments.dept_id` 都应该创建索引。
  - 否则，数据库只能进行全表扫描（Nested Loop Join），性能极差。

- **只选择必要的字段**：避免使用 `SELECT *`，只取出需要的字段。

  sql

  ```
  -- 优化前
  SELECT * FROM table_a a JOIN table_b b ON a.id = b.a_id;
  
  -- 优化后
  SELECT a.name, b.date, b.amount FROM table_a a JOIN table_b b ON a.id = b.a_id;
  ```

  数据量越少，参与JOIN和网络传输的时间就越短。

- **减少JOIN前的数据量**：在JOIN之前，先用子查询或临时表过滤掉不需要的数据。

  sql

  ```
  SELECT ... 
  FROM (SELECT * FROM employees WHERE hire_date > '2020-01-01') e -- 先过滤
  JOIN departments d ON e.dept_id = d.dept_id;
  ```

2. 高级优化（应对大数据场景）

- **理解执行计划（EXPLAIN）**：优化JOIN的首要任务是**使用 `EXPLAIN` 命令**分析SQL的执行计划。重点关注：
  - **JOIN类型**（type列）：至少应该是 `ref` 或 `eq_ref`，而不是 `ALL`（全表扫描）。
  - **使用的索引**（key列）：确认是否使用了我们创建的索引。
  - **额外信息**（Extra列）：注意是否有 `Using filesort` 或 `Using temporary`，这通常是性能瓶颈。

### LEFT JOIN和RIGHT JOIIN的区别，会有数据膨胀的问题吗？如何避免？

**数据膨胀**指的是：JOIN 后结果集的行数远远超过了左表（对于 LEFT JOIN）或右表（对于 RIGHT JOIN）原本的行数。

**根本原因：**
当基准表中的**一条记录**，根据关联键（ON condition）在另一张表中匹配到了**多条记录**时，就会发生数据膨胀。基准表的这一条记录会被重复多次，与另一张表的每一条匹配记录组合成新行。

避免数据膨胀的关键在于**确保 JOIN 的粒度（Granularity）一致**，即在关联前确保关联键在两张表中都是唯一的，或者明确意识到膨胀的存在并正确处理。

1. **提前聚合（Pre-aggregation）**
   这是最常用、最有效的方法。在 JOIN 之前，先对可能引起膨胀的表进行聚合，确保关联键唯一。
   **问题SQL：**

   sql

   ```
   SELECT o.order_id, c.country
   FROM orders o
   LEFT JOIN customers c ON o.customer_id = c.customer_id; -- c表有多条记录，导致膨胀
   ```

   **优化后：** 我们先聚合 `customers` 表，只取每个客户的最新国籍（或其他唯一值）。

   sql

   ```
   WITH latest_customer AS (
     SELECT customer_id, country
     FROM customers
     QUALIFY ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY year DESC) = 1 -- 取最新记录
     -- 或者使用 GROUP BY，如 SELECT customer_id, MAX(country) as country ... GROUP BY customer_id
   )
   SELECT o.order_id, lc.country
   FROM orders o
   LEFT JOIN latest_customer lc ON o.customer_id = lc.customer_id; -- 此时关联键唯一，不会膨胀
   ```

2. **使用 DISTINCT 或 GROUP BY 去重**
   如果膨胀已经发生且业务上不需要多条记录，可以在最终 SELECT 时去重。**但要极度谨慎**，因为盲目去重可能会错误地丢失有效信息。

   sql

   ```
   SELECT DISTINCT o.order_id, c.country -- 使用DISTINCT去重
   FROM orders o
   LEFT JOIN customers c ON o.customer_id = c.customer_id;
   ```

3. **先过滤，再 JOIN**
   如果另一张表的多条记录中只有部分是你关心的，先用子查询进行过滤，减少匹配的多条记录数量。

   sql

   ```mysql
   SELECT o.order_id, c.country
   FROM orders o
   LEFT JOIN (
     SELECT * FROM customers WHERE year = 2021 -- 先过滤出2021年的记录
   ) c ON o.customer_id = c.customer_id;
   ```



### 窗口函数和聚合函数的区别？

最核心的区别在于：**聚合函数会将多行数据“折叠”成一行摘要结果，而窗口函数会为每一行都提供一个计算结果，同时保留原有的所有行明细。**

1. 聚合函数 (Aggregate Functions)

- **作用**：**将一组行分组（GROUP BY）后，计算出一个单一的汇总值。** 它减少了结果集的行数。

- **常见函数**：`SUM()`, `COUNT()`, `AVG()`, `MAX()`, `MIN()`

- **如何使用**：几乎总是与 `GROUP BY` 子句配合使用，否则会对所有行计算一个总值。

- **示例查询**：计算每个销售人员的总销售额。

  sql

  ```
  SELECT salesperson, SUM(sale_amount) AS total_sales
  FROM sales
  GROUP BY salesperson;
  ```

- **结果**：多行被“折叠”成了分组后的摘要行。

  | salesperson | total_sales |                |
  | :---------- | :---------- | -------------- |
  | Alice       | 250         | -- (100 + 150) |
  | Bob         | 250         | -- (200 + 50)  |

**关键点**：结果集的行数从4行变成了2行（按销售人员分组）。

2. 窗口函数 (Window Functions)

- **作用**：**为结果集中的每一行计算一个基于“窗口”（一个与该行相关的行集合）的汇总值。它不会合并行，会保留所有原始明细。**

- **常见函数**：

  - **聚合类窗口函数**：`SUM() OVER()`, `AVG() OVER()`
  - **排名类窗口函数**：`ROW_NUMBER()`, `RANK()`, `DENSE_RANK()`
  - **偏移分析函数**：`LAG()`, `LEAD()`, `FIRST_VALUE()`

- **核心语法**：必须使用 `OVER()` 子句来定义计算数据的“窗口”。`OVER()` 中可以指定：

  - `PARTITION BY`：类似于 `GROUP BY`，用于分组，但不会折叠行。
  - `ORDER BY`：定义窗口内数据的排序顺序，这对于计算累计、移动平均和排名至关重要。
  - `window_frame`：定义更精确的窗口范围（如 `ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW` 表示从第一行到当前行）。

- **示例查询1**：计算每个销售人员的总销售额，但同时保留每一笔销售的原始记录。

  sql

  ```
  SELECT salesperson,
         sale_amount,
         SUM(sale_amount) OVER(PARTITION BY salesperson) AS total_sales
  FROM sales;
  ```

- **结果**：原始明细行都被保留，并为每一行都添加了汇总信息。

  | salesperson | sale_amount | total_sales |                                |
  | :---------- | :---------- | :---------- | ------------------------------ |
  | Alice       | 100         | 250         |                                |
  | Alice       | 150         | 250         | -- Alice的总销售额显示在每一行 |
  | Bob         | 200         | 250         |                                |
  | Bob         | 50          | 250         | -- Bob的总销售额显示在每一行   |

- **示例查询2**：计算每个销售人员内部，每笔销售额的排名。

  sql

  ```
  SELECT salesperson,
         sale_amount,
         RANK() OVER(PARTITION BY salesperson ORDER BY sale_amount DESC) AS sales_rank
  FROM sales;
  ```

- **结果**：

  | salesperson | sale_amount | sales_rank |                        |
  | :---------- | :---------- | :--------- | ---------------------- |
  | Alice       | 150         | 1          |                        |
  | Alice       | 100         | 2          | -- 在Alice组内排名第二 |
  | Bob         | 200         | 1          |                        |
  | Bob         | 50          | 2          | -- 在Bob组内排名第二   |

**关键点**：结果集的行数保持不变（仍然是4行），但为每一行都增加了新的计算列。

对比总结

| 特性           | 聚合函数                           | 窗口函数                                             |
| :------------- | :--------------------------------- | :--------------------------------------------------- |
| **结果集行数** | **减少**（折叠为分组摘要）         | **不变**（保留所有原始行）                           |
| **核心子句**   | `GROUP BY`                         | `OVER()`                                             |
| **输出内容**   | 每组一条摘要结果                   | 为每一行添加计算列                                   |
| **典型用途**   | 制作汇总报表、仪表盘（总计、平均） | 计算排名、百分比、累计值、移动平均，同时需要看到明细 |



### TCP协议分几层

这是一个非常基础的计算机网络问题。TCP协议位于**传输层（Transport Layer）**。

TCP/IP协议

| TCP/IP 层数 | 层名称              | 功能描述                                                     | 对应协议                                           |
| :---------- | :------------------ | :----------------------------------------------------------- | :------------------------------------------------- |
| 第4层       | 应用层              | 将OSI的应用层、表示层、会话层功能合并，直接为用户进程提供服务 | HTTP, FTP, DNS, SMTP **（以及基于TCP/UDP的应用）** |
| 第3层       | 传输层（Transport） | **提供端到端的通信，负责数据的分段、端口寻址、流量控制和差错控制** | **TCP, UDP**                                       |
| 第2层       | 网络层（Internet）  | 负责主机到主机的通信，逻辑寻址（IP地址）和路由               | IP, ICMP, ARP                                      |
| 第1层       | 网络接口层          | 相当于OSI的数据链路层和物理层，负责在物理网络上传输数据帧    | Ethernet, WiFi                                     |

### Spark为什么快？其执行过程，特点？宽依赖窄依赖？

好的，面试官。Apache Spark 之所以速度快，其核心在于它颠覆了 MapReduce 基于磁盘的迭代计算模型，转而采用基于内存的计算和一套极其高效的执行引擎。简单来说，Spark 将整个计算流程构建成一个有向无环图（DAG），并通过其 DAGScheduler 对这个图进行全局优化和拆解。它将复杂的计算任务划分为多个阶段（Stage），阶段划分的关键依据就是 RDD 之间的依赖关系，也就是宽依赖和窄依赖。

窄依赖意味着父 RDD 的一个分区最多只被子 RDD 的一个分区所使用，像 map、filter 这样的操作都属于窄依赖，它们允许 Spark 将多个操作管道化（pipeline）在一个任务内顺序执行，完全避免了不必要的中间数据落地和网络传输，这是其高效的基础。而宽依赖则代表父 RDD 的一个分区数据会被子 RDD 的多个分区使用，例如 groupByKey 或未经优化的 join 操作，这必然会引起 Shuffle——也就是数据需要在网络上传送和重新分组。

宽依赖是划分不同 Stage 的边界，因为 Shuffle 之后数据需要重新洗牌，下一个 Stage 必须等待上一个 Stage 的所有任务全部完成才能开始。正是这种基于依赖关系的 Stage 划分机制，使得 Spark 的调度器能够实现精细化的任务调度和容错。在此之上，Spark SQL 的 Catalyst 优化器会对代码进行诸如谓词下推、列剪裁等高级优化，而 Tungsten 引擎则通过堆外内存管理和代码生成等技术，突破了 JVM 在内存和计算效率上的瓶颈，这几者共同作用，最终让 Spark 实现了远超前代技术的计算性能。



### 讲排序算法

- **冒泡排序**：它反复地遍历列表，比较相邻元素，如果它们的顺序错误就交换它们。这个过程就像气泡一样，最大的元素会逐渐“浮”到顶端。它的实现非常简单，但效率也是最低的，时间复杂度为 O(n²)，通常仅用于教学理解概念。
- **快速排序**：这是一种采用**分治**思想的高效算法，在实践中应用非常广泛。它首先选择一个“基准”元素，然后将数组重新排列，所有比基准小的元素放在它前面，所有比基准大的元素放在后面，这个操作称为“分区”。此后，递归地对基准前、后的子数组进行相同操作。快速排序的平均时间复杂度为 O(n log n)，虽然最坏情况（比如数组已经有序）会退化为 O(n²)，但通过随机选择基准等技巧可以极大避免。它是在原址上排序的，但不是稳定的。
- **归并排序**：同样是分治思想的典范，但思路与快排不同。它将数组递归地分成两半，直到每个子数组只剩一个元素，然后将这些有序的子数组再两两“合并”成一个新的有序数组。这个过程需要额外的空间来存储合并后的结果。它的最大优点是**稳定**，并且任何情况下都能保证 O(n log n) 的时间复杂度，非常可靠，因此常用于对稳定性有要求或数据量巨大的外部排序（如数据库中的排序-合并连接）。
- **堆排序**：它利用了一种叫做“堆”的完全二叉树结构。首先将数组构建成一个最大堆，使得堆顶元素是最大值。然后将堆顶元素（最大值）与堆的最后一个元素交换，并缩小堆的范围，再重新调整结构以维持堆的性质，如此反复，就能得到一个从小到大排序的数组。堆排序的时间复杂度也是 O(n log n)，并且是原址排序，但不稳定。它在处理大数据集时效率比较稳定，没有快排那样的最坏情况风险。



### 红黑树，平衡二叉树，搜索二叉树，B树，B+树分别是什么

1. 二叉搜索树

- **它是什么？** 这是所有后续结构的基础。它是一棵二叉树，并满足一个简单性质：对于任意节点，其**左子树**上所有节点的值都**小于**它，其**右子树**上所有节点的值都**大于**它。
- **核心特点**：这个性质保证了**中序遍历**BST可以得到一个有序序列。
- **缺点**：BST的性能严重依赖于树的形状。如果插入的顺序是近乎有序的（如 1, 2, 3, 4...），BST会退化成一条**链表**，此时查找的时间复杂度会从平均的 **O(log n)** 恶化到最坏的 **O(n)**。
- **为什么需要其他树？** 正是为了克服BST可能退化的缺陷，人们发明了各种**自平衡的**二叉搜索树。

2. 平衡二叉树

- **它是什么？** 这不是某一种特定的树，而是一类树的统称。凡是**通过特定操作维持左右子树高度大致相等**，从而防止退化的二叉搜索树，都叫平衡二叉树。
- **核心目标**：保证树的高度始终在对数级别，即 **O(log n)**，从而保证查找、插入、删除操作的最坏时间复杂度也是 **O(log n)**。
- **常见代表**：**AVL树**和**红黑树**是最著名的两种平衡二叉树。

3. 红黑树

- **它是什么？** 红黑树是平衡二叉树的一种具体实现。它通过一组额外的规则（“红黑规则”）和**旋转**操作来维持大致的平衡，而不是像AVL树那样追求严格的平衡。
- **核心规则**（简化理解）：
  1. 每个节点非红即黑。
  2. 根节点是黑色的。
  3. 所有叶子节点（NIL节点）是黑色的。
  4. 红色节点的两个子节点必须是黑色的。（即不能有相邻的红色节点）
  5. **路径黑色平衡**：从任意一个节点出发，到其所有后代叶子节点的路径中，包含的黑色节点数量必须相等（这条规则是 “平衡” 的核心，确保最长路径不超过最短路径的 2 倍）。
- **特点**：这些规则保证了从根到叶子的**最长可能路径**不会超过**最短可能路径**的两倍，从而实现了“大致平衡”。虽然它没有AVL树那样绝对的平衡，但维持平衡所需的**旋转操作更少**。
- **应用场景**：由于其插入/删除性能优于AVL树，常用于需要频繁修改的场景。例如：
  - **Java** 中的 `TreeMap`, `TreeSet`, `HashMap`（链表转树后的冲突解决）
  - **C++** STL 中的 `map`, `set`
  - **Linux** 内核的进程调度

4. B树

- **它是什么？** B树是一种**多路搜索树**， designed for disks. 它不再是二叉树，而是一个节点可以有**多个子节点**（称为 **M** 阶树，M>2）和**多个键**。
- **核心特点**：
  - **矮胖**：通过增加每个节点的分支数（度），大大降低了树的高度。
  - **针对磁盘I/O优化**：磁盘读写以“页”为单位。B树的一个节点大小通常被设计为等于一个磁盘页的大小。这样，一次磁盘I/O就可以加载一个包含大量键的节点，然后在内存中进行二分查找，极大地减少了磁盘访问次数（树的高度决定I/O次数）。这是B树系列相对于二叉树的**根本优势**。
- **应用场景**：主要用于**文件系统**和**某些数据库的索引**（如MongoDB）。

5. B+树

- **它是什么？** B+树是B树的一种变体，是**现代关系型数据库索引的绝对主流结构**。

- **与B树的核心区别**：

  1. **数据只存储在叶子节点**：B树的内部节点既存键也存数据指针；而B+树的**内部节点只存键**，作为导航的“索引”，**所有数据记录都存放在叶子节点**中。
  2. **叶子节点通过指针串联**：所有叶子节点之间用一个双向链表连接起来。

- **B+树的优势**（为什么数据库最爱它）：

  1. **更稳定的查询性能**：任何查找都必须走到叶子节点，路径长度相同。
  2. **更低的树高**：因为内部节点不存数据，同样大小的节点可以存储更多的键，导致树更矮胖，I/O次数更少。
  3. **极强的范围查询能力**：由于叶子节点是链表连接的，一旦找到了范围查询的起点，就可以顺序扫描链表快速获取所有数据，而无需像B树那样回溯到父节点。**这是B+树相对于B树的决定性优势**。

- **应用场景**：**几乎所有关系型数据库**（MySQL InnoDB, PostgreSQL, Oracle等）的索引都使用B+树。


### mysql乐观锁，悲观锁

**1. 悲观锁（Pessimistic Lock）**

**核心思想**：假设并发访问会发生冲突，因此在整个数据操作过程中，始终持有锁，阻止其他事务对数据进行修改。
**适用场景**：并发冲突频繁、写操作较多的场景（如库存扣减、金融交易）。

**实现方式**

MySQL 中通过 `FOR UPDATE` 或 `LOCK IN SHARE MODE` 在 SQL 语句中显式加锁：

- `FOR UPDATE`：加**排他锁**（写锁），阻止其他事务读取或修改该数据。
- `LOCK IN SHARE MODE`：加**共享锁**（读锁），允许其他事务读，但阻止写。

**2. 乐观锁（Optimistic Lock）**

**核心思想**：假设并发访问不会发生冲突，因此操作时不加锁，仅在提交时检查数据是否被其他事务修改过。
**适用场景**：并发冲突少、读操作较多的场景（如商品详情浏览、信息查询）。

**实现方式**

通过**版本号机制**或**时间戳机制**实现：

1. 在表中增加一个版本字段（如 `version`），初始值为 0。
2. 读取数据时，同时获取版本号。
3. 更新数据时，检查当前版本号是否与读取时一致：
   - 一致：更新数据并将版本号 +1。
   - 不一致：说明数据已被修改，放弃更新或重试。

### kafka高性能原因

1. 磁盘用**顺序读写 + 页缓存**，规避随机 IO 瓶颈；
2. 靠**分区机制**实现并行读写与负载均衡；
3. 读取用**零复制**减少数据拷贝，降低开销；
4. 支持**批量处理 + 消息压缩**，减少网络 / 存储成本；
5. 消费者**拉取模式**适配自身处理能力，结合轻量级索引提升查询效率。

### 反转链表

### 判断链表是否有环

### 从整数字符串中提取最大最小值



# 二面

> 二面问项目，思维框架，可能会有算法手撕

### 设计数据表

面试官，以上是一个符合第三范式（3NF）的基础设计。在实际项目中，我们还会根据业务需求进行优化：

- **读写分离**：对于 `view_count` 这种高频更新的字段，可以考虑与核心内容表分离，或使用缓存来更新。
- **分库分表**：如果文章量巨大，`articles` 表可能需要按时间或按用户进行分表（Sharding）。
- **设置主键与索引**：主键唯一标识记录（建议自增 ID，避免业务字段）；对查询频繁的字段（如订单号、用户 ID）建索引，但避免过多索引（拖慢写入）。

我的设计理念是：**首先保证范式和数据完整性，然后在明确的性能瓶颈出现时，再有针对性地进行反范式优化。** 我会优先使用索引、查询优化和缓存等手段，最后才考虑修改表结构。

## 介绍项目

做中药材智能识别的项目，是因为我的导师和上海中医药大学有合作，他们那边对中药材的鉴定一般使用专业的仪器检测化学性质，因此会探索会不会有其他成本更低的鉴定药材真伪的方法。我们先对多种药材的显微图像进行了采集，清洗数据，进行标准化，然后使用DETR模型来训练，最后实现一个端到端的自动鉴定流程。当然我们也遇到了困难，比如一开始的预测精度不足，没有达到别人使用DETR模型的准确度，因此我们排除了模型的问题，把重点定位到了数据集上，我们选择增加了新的数据集以及对数据集进行了增强，最后的预测准确率也上来。

## 项目提问

**一、基于深度学习的中药材显微图像识别系统项目相关问题**

1. 在主导 400 倍显微图像数据采集过程中，你遇到过哪些特殊情况导致图像质量不达标？比如光线干扰、样本摆放偏差等，当时是如何解决这些问题来保证数据有效性的？
2. 标准化处理 3000 + 中药材图像时，采用了哪些具体的标准化方法？不同种类中药材图像在标准化过程中是否存在差异，你是如何针对性调整处理策略的？
3. 人工标注关键细胞特征时，如何定义 “关键细胞特征”？有没有制定统一的标注标准来确保不同标注人员之间的一致性？若出现标注争议，你是如何协调解决的？
4. 设计融合 DETR 目标检测与 ResNet 分类的算法框架时，为什么选择这两种模型进行融合？在融合过程中，如何处理两种模型输出结果的衔接问题？有没有尝试过其他模型融合方案，效果如何？

DETR（目标检测模型）：优势在于端到端目标检测，无需人工设计锚点，能自动学习显微图像中关键细胞的空间位置信息，精准输出细胞区域的边界框（如人参导管细胞、当归韧皮部细胞的位置），解决 “哪里是关键细胞” 的定位问题。
ResNet（分类模型）：通过残差连接突破深层网络梯度消失问题，擅长提取图像的高层语义特征（如细胞的形状、纹理、颜色等细节），能高效区分不同中药材的细胞特征差异，解决 “这是哪种中药材细胞” 的分类问题。

1. 结合对比学习与集成方法提升细胞粗分类准确率时，对比学习中选择的对比样本是如何确定的？集成方法具体采用了哪种形式，比如投票法、加权平均法等，选择该方法的依据是什么？
2. 利用正则化与注意力机制优化模型以降低过拟合率时，使用的是哪种正则化方法，比如 L1 正则、L2 正则、Dropout 等？注意力机制是如何定位到关键特征区域，从而帮助模型提升泛化能力的？

L2 正则化（权重衰减）
在模型训练的损失函数中加入权重平方项（系数 λ=0.001），对 DETR 的 Transformer 编码器 / 解码器权重和 ResNet 的卷积层权重进行约束。
作用：抑制权重过大的参数，避免模型过度依赖训练集中的噪声特征（如显微图像中的染色不均、杂质颗粒）。
适配性：中药材显微图像的背景复杂（如细胞壁纹理与背景的灰度差异小），L2 正则化能有效防止模型 “记住” 这些非关键噪声。

1. 在人参、当归等 15 类中药材测试中，目标检测框准确率达 94.12%，这个准确率是通过什么评价指标计算得出的？对于检测准确率较低的中药材种类，你分析过具体原因吗，是否有针对性的优化思路？

**二、上海赞意文化传播有限公司数据分析岗位相关问题**

1. 开发 Python 自动化程序批量下载 500 余条抖音视频时，使用了哪些 Python 库或工具？有没有遇到抖音平台的反爬机制限制，你是如何规避这些限制确保下载顺利进行的？
2. 程序自动提炼抖音视频关键内容的实现逻辑是什么？是基于视频标题、字幕提取，还是通过图像识别、语音转文字分析核心信息？提炼效果如何评估，是否有进行人工验证？

Whisper（OpenAI）

1. 抓取 1 万余条抖音评论进行情感分析时，采用了哪种情感分析模型或方法？如何处理评论中的 slang（俚语）、谐音词等特殊表述，以提高情感判断的准确性？

BERT(哈工大)

1. 输出的可落地洞察具体包含哪些内容形式，比如用户偏好总结、热门话题趋势建议等？这些洞察是如何转化为实际业务动作，帮助业务部门解决具体问题的，能否举例说明？
2. 搭建自动热点监测系统时，如何定义 “热门话题” 的判定标准，比如浏览量、讨论量、增长速度等指标的阈值是如何设定的？系统是通过什么方式实时获取小红书、抖音平台数据，确保热点捕捉及时性的？
3. 每周捕捉 100 + 热门话题后，会以怎样的形式将这些信息提供给投流部门？投流部门基于这些数据支持做出了哪些调整，有没有反馈过数据对投流效果的具体影响？
4. 为乐高、学而思、合生元、纯悦等 30 余个品牌撰写数据分析报告时，不同行业品牌的报告侧重点有何不同？比如乐高可能更关注儿童用户偏好，学而思更关注学习效果反馈，你是如何根据品牌特性调整报告内容的？
5. 在为多个品牌服务过程中，是否出现过不同品牌需求冲突或数据获取难度差异较大的情况？你是如何平衡多品牌需求，确保每个品牌数据分析工作都能按时保质完成的？
6. 回顾这段数据分析工作，你认为自己在数据处理效率、洞察提炼深度等方面还有哪些可以提升的地方？如果再做类似项目，你会在哪些环节优化工作流程？
